# ğŸ­ Centro de InformaciÃ³n Colombina

Un sistema integral de inteligencia artificial especializado en **Colombina**, la empresa lÃ­der en dulces y confiterÃ­a de Colombia y LatinoamÃ©rica. Este centro combina web scraping, procesamiento de documentos, anÃ¡lisis de contenido y mÃºltiples interfaces de IA para brindar informaciÃ³n completa sobre la empresa.

## ğŸŒŸ CaracterÃ­sticas Principales

- **ğŸ’¬ Chatbot Interactivo**: ConversaciÃ³n natural usando OpenAI GPT-4o
- **ğŸ” Sistema Q&A**: Consultas especÃ­ficas con modelos locales (Ollama)
- **â“ Generador de FAQs**: CreaciÃ³n automÃ¡tica de preguntas frecuentes
- **ğŸ“‹ Resumen Ejecutivo**: AnÃ¡lisis integral de informaciÃ³n corporativa
- **ğŸ•·ï¸ Web Scraping Avanzado**: ExtracciÃ³n automÃ¡tica del sitio oficial de Colombina
- **ğŸ“„ Procesamiento de PDFs**: ExtracciÃ³n de informes anuales y documentos corporativos
- **ğŸ”„ Pipeline de Chunking**: DivisiÃ³n inteligente de contenido para RAG
- **ğŸ“Š Logging Avanzado**: Sistema completo de trazabilidad y monitoreo

## ğŸš€ TecnologÃ­as Utilizadas

### Backend y IA
- **Python 3.13+**
- **LangChain** - Framework para LLMs y RAG
- **OpenAI GPT-4o** - Modelo principal para el chatbot
- **Ollama** - Modelos locales (gpt-oss:20b)
- **Streamlit** - Interfaz web multi-tab

### Web Scraping y Procesamiento
- **Selenium** - AutomatizaciÃ³n web avanzada
- **BeautifulSoup4** - Parsing HTML
- **PyPDF2** - ExtracciÃ³n de contenido PDF
- **RecursiveCharacterTextSplitter** - Chunking inteligente

### Almacenamiento y Logging
- **JSON** - Base de conocimiento estructurada
- **CSV** - ExportaciÃ³n de datos
- **Logging personalizado** - Sistema de trazabilidad

## ğŸ“‹ Requisitos Previos

- Python 3.13 o superior
- API Key de OpenAI
- Ollama instalado (para funciones Q&A y FAQ)
- Chrome/Chromium (para web scraping)
- ConexiÃ³n a internet

## ğŸ”§ InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone <url-del-repositorio>
cd chatbot_colombina
```

2. **Instalar dependencias**
```bash
uv venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows
uv pip install -r pyproject.toml
```

3. **Configurar variables de entorno**
```bash
# Crear archivo .env en la raÃ­z del proyecto
echo "OPENAI_API_KEY=tu_api_key_aqui" > .env
```

4. **Instalar Ollama (opcional, para Q&A local)**
```bash
# Instalar Ollama desde https://ollama.ai
ollama pull gpt-oss:20b
```

## ğŸƒâ€â™‚ï¸ Uso

### Interfaz Principal (Streamlit)
```bash
streamlit run chatbot.py
```

La aplicaciÃ³n incluye 4 pestaÃ±as principales:

#### ğŸ” **Consulta Q&A**
- Sistema de preguntas y respuestas usando modelos locales
- Preguntas predefinidas sobre Colombina
- ParÃ¡metros configurables (temperatura, top_p)

#### â“ **Preguntas Frecuentes** 
- GeneraciÃ³n automÃ¡tica de FAQs basadas en la base de conocimiento
- ExportaciÃ³n en formato texto
- AnÃ¡lisis de 25 fragmentos de contenido mÃ¡s relevantes

#### ğŸ“‹ **Resumen Ejecutivo**
- Resumen completo de informaciÃ³n corporativa
- AnÃ¡lisis de historia, sostenibilidad, productos y logros
- ExportaciÃ³n en formato texto

#### ğŸ’¬ **Chatbot Interactivo**
- ConversaciÃ³n natural con GPT-4o
- Memoria de conversaciÃ³n por sesiÃ³n
- Respuestas especializadas en Colombina

### Funciones Individuales

#### Web Scraping
```bash
# ExtracciÃ³n bÃ¡sica de links
python web_scraping/scripts/extract_colombina_links.py

# Scraping avanzado con contenido completo
python web_scraping/scripts/advanced_scraper.py
```

#### Procesamiento de Datos
```bash
# Limpiar archivos markdown y crear la base de conocimiento
python preprocessing/clean_md_files.py

# Limpiar base de conocimiento
python knowledge_base/clean_kb.py

# Generar chunks
python chunking/chunking.py
```

#### Sistemas de IA Individuales
```bash
# Generar FAQs
python llm/FAQ/faq_ollama.py

# Sistema Q&A
python llm/QA/qa_ollama.py

# Generar resumen
python llm/summary/generate_summary.py
```

## ğŸ“ Estructura del Proyecto

```
chatbot_colombina/
â”œâ”€â”€ chatbot.py                     # ğŸ¯ Interfaz principal Streamlit
â”œâ”€â”€ requirements.txt               # ğŸ“¦ Dependencias del proyecto
â”œâ”€â”€ pyproject.toml                # âš™ï¸ ConfiguraciÃ³n del proyecto
â”œâ”€â”€ 
â”œâ”€â”€ llm/                          # ğŸ¤– MÃ³dulos de IA
â”‚   â”œâ”€â”€ llm_openai.py            # OpenAI GPT-4o integration
â”‚   â”œâ”€â”€ FAQ/
â”‚   â”‚   â””â”€â”€ faq_openai.py        # Generador de FAQs
â”‚   â”œâ”€â”€ QA/
â”‚   â”‚   â””â”€â”€ qa_ollama.py         # Sistema Q&A con Ollama
â”‚   â””â”€â”€ summary/
â”‚       â””â”€â”€ generate_summary.py  # Generador de resÃºmenes
â”‚
â”œâ”€â”€ web_scraping/                 # ğŸ•·ï¸ Sistema de scraping
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ extract_colombina_links.py
â”‚   â”‚   â””â”€â”€ advanced_scraper.py   # Scraper principal
â”‚   â”œâ”€â”€ colombina_advanced/       # Datos extraÃ­dos
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚       â”œâ”€â”€ noticias/
â”‚   â”‚       â””â”€â”€ otros/
â”‚   â””â”€â”€ pdf_extraction/           # PDFs procesados
â”‚       â””â”€â”€ markdown/
â”‚
â”œâ”€â”€ preprocessing/                # ğŸ”„ Procesamiento de datos
â”‚   â”œâ”€â”€ clean_md_files.py        # Limpieza de markdown
â”‚   â”œâ”€â”€ selected_md_files/       # Archivos seleccionados
â”‚   â””â”€â”€ cleaned_md_files/        # Archivos procesados
â”‚
â”œâ”€â”€ chunking/                     # âœ‚ï¸ DivisiÃ³n de contenido
â”‚   â”œâ”€â”€ chunking.py              # GeneraciÃ³n de chunks
â”‚   â””â”€â”€ chunks.json              # Chunks para RAG
â”‚
â”œâ”€â”€ knowledge_base/              # ğŸ“š Base de conocimiento
â”‚   â”œâ”€â”€ knowledge_base.txt       # Base original
â”‚   â”œâ”€â”€ improved_knowledge_base.txt # Base mejorada
â”‚   â””â”€â”€ clean_kb.py             # Script de limpieza
â”‚
â”œâ”€â”€ logging_util/               # ğŸ“Š Sistema de logging
â”‚   â”œâ”€â”€ logger.py              # ConfiguraciÃ³n de logs
â”‚   â””â”€â”€ logs/                  # Archivos de log
â”‚
â””â”€â”€ tests/                     # ğŸ§ª Pruebas y anÃ¡lisis
    â””â”€â”€ Taller1.ipynb         # Notebooks de evaluaciÃ³n
```

## âš™ï¸ ConfiguraciÃ³n Avanzada

### ParÃ¡metros del Modelo

#### Chatbot Interactivo (GPT-4o)
- **ğŸŒ¡ï¸ Temperatura (0.0-1.0)**: Creatividad de respuestas (default: 0.1)
- **ğŸ¯ Top P (0.0-1.0)**: Diversidad de vocabulario (default: 0.9)

#### Sistema Q&A (Ollama)
- **Modelo**: gpt-oss:20b (configurable)
- **Chunks mÃ¡ximos**: 25 fragmentos por consulta
- **TamaÃ±o de chunk**: 1000 caracteres con overlap de 200

#### Web Scraping
- **CategorÃ­as**: noticias, productos, sostenibilidad, otros
- **Formato de salida**: Markdown enriquecido con metadatos
- **LÃ­mite de URLs**: Configurable (294 URLs totales detectadas)

### Sistema de Logging
```python
# ConfiguraciÃ³n en logging_util/logger.py
- RotaciÃ³n automÃ¡tica de archivos
- Niveles: DEBUG, INFO, WARNING, ERROR
- Formato timestamped con colores
- Archivos separados por mÃ³dulo
```

## ğŸ’¬ Ejemplos de Uso

### Preguntas de Ejemplo para Q&A
- "Â¿CÃ³mo se llama el programa de Colombina para acompaÃ±ar a sus proveedores y emprendedores?"
- "Â¿QuÃ© porcentaje de la energÃ­a elÃ©ctrica que utiliza Colombina en Colombia proviene de fuentes renovables?"
- "Â¿CuÃ¡les son los principales logros de Colombina en materia de sostenibilidad relacionados con la energÃ­a y el agua?"
- "Â¿CuÃ¡ndo y cÃ³mo fue fundada Colombina?"
- "Â¿En cuÃ¡ntos paÃ­ses tiene presencia la empresa actualmente?"

### Consultas para el Chatbot
- "Â¿QuÃ© productos fabrica Colombina?"
- "CuÃ©ntame sobre la historia de Bon Bon Bum"
- "Â¿QuÃ© ingredientes tienen los chocolates Nucita?"
- "Â¿DÃ³nde puedo comprar productos Colombina?"
- "Â¿CuÃ¡les son las iniciativas de sostenibilidad de la empresa?"

## ğŸ” Base de Conocimiento

### Fuentes de InformaciÃ³n
- **Sitio Web Oficial**: 294 URLs categorizadas y procesadas
- **Informes Anuales**: PDFs extraÃ­dos y convertidos a texto
- **Documentos Corporativos**: CÃ³digos de conducta, polÃ­ticas
- **Noticias**: Lanzamientos, colaboraciones, logros

### Cobertura TemÃ¡tica
- **ğŸ“ˆ Historia y ExpansiÃ³n**: FundaciÃ³n, crecimiento, internacionalizaciÃ³n
- **ğŸŒ± Sostenibilidad**: EnergÃ­a renovable, gestiÃ³n de residuos, huella de carbono
- **ğŸ¬ Productos**: CatÃ¡logo completo, marcas, innovaciones
- **ğŸ‘¥ Responsabilidad Social**: Programas comunitarios, equidad de gÃ©nero
- **ğŸ’¼ InformaciÃ³n Corporativa**: Gobierno, finanzas, certificaciones
- **ğŸ“ Contacto**: Proveedores, servicio al cliente, sedes

## ğŸ› ï¸ Desarrollo y Arquitectura

### Flujo de Datos
1. **ExtracciÃ³n**: [`advanced_scraper.py`](web_scraping/scripts/advanced_scraper.py) â†’ sitio web
2. **Procesamiento**: [`clean_md_files.py`](preprocessing/clean_md_files.py) â†’ archivos limpios
3. **Chunking**: [`chunking.py`](chunking/chunking.py) â†’ fragmentos para RAG
4. **IA**: Modelos locales (Ollama) y remotos (OpenAI)

### Componentes Clave

#### [`chatbot.py`](chatbot.py)
Interfaz principal con 4 tabs especializados, configuraciÃ³n de parÃ¡metros y manejo de estado.

#### [`llm/llm_openai.py`](llm/llm_openai.py)
Core del chatbot con prompt especializado y manejo de errores.

#### [`web_scraping/scripts/advanced_scraper.py`](web_scraping/scripts/advanced_scraper.py)
Scraper robusto con categorizaciÃ³n automÃ¡tica y manejo de errores.

#### [`chunking/chunking.py`](chunking/chunking.py)
Sistema de divisiÃ³n inteligente de contenido para optimizar el RAG.

### Agregar Nuevas Funcionalidades

1. **Modificar prompts**: Editar templates en mÃ³dulos LLM
2. **Agregar fuentes**: Extender el scraper o agregar procesadores
3. **Nuevos modelos**: Integrar en [`llm/`](llm/) con configuraciÃ³n similar
4. **Mejorar chunking**: Ajustar parÃ¡metros en [`chunking.py`](chunking/chunking.py)
5. **Extend UI**: Agregar tabs en [`chatbot.py`](chatbot.py)

## ğŸ“Š MÃ©tricas y EvaluaciÃ³n

### Cobertura de InformaciÃ³n
- **294 URLs** procesadas del sitio oficial
- **130 chunks** generados para RAG
- **26 documentos** principales procesados
- **Multiple PDFs** de informes anuales integrados

### Rendimiento del Sistema
- **Tiempo de respuesta Q&A**: ~1-2 minutos (modelo local)
- **Tiempo de respuesta Chatbot**: ~5-10 segundos (OpenAI)
- **PrecisiÃ³n evaluada**: Sistema de evaluaciÃ³n en [`tests/Taller1.ipynb`](tests/Taller1.ipynb)

## ğŸ”’ Seguridad y Mejores PrÃ¡cticas

- âœ… API Keys en variables de entorno
- âœ… Logs sin informaciÃ³n sensible
- âœ… ValidaciÃ³n de entrada en todos los mÃ³dulos
- âœ… Manejo robusto de errores y excepciones
- âœ… SeparaciÃ³n clara entre datos y cÃ³digo
- âœ… Licencia Apache 2.0 para uso comercial

## ğŸ› SoluciÃ³n de Problemas

### Errores Comunes

#### "Falta la API Key de OpenAI"
```bash
# Verificar archivo .env
cat .env
# Debe contener: OPENAI_API_KEY=sk-...
```

#### "Ollama model not found"
```bash
# Instalar modelo requerido
ollama pull gpt-oss:20b
```

#### Error en Web Scraping
```bash
# Verificar Chrome/Chromium instalado
# Revisar logs en logging_util/logs/
```

#### Chunks no generados
```bash
# Verificar base de conocimiento
python chunking/chunking.py
# Revisar knowledge_base/improved_knowledge_base.txt
```

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia Apache 2.0. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸš§ Estado del Proyecto

**VersiÃ³n actual: 1.0.0**

### Completado âœ…
- Sistema completo de web scraping
- Pipeline de procesamiento de datos
- 4 interfaces de IA especializadas
- Base de conocimiento integral
- Sistema de logging avanzado
- EvaluaciÃ³n y mÃ©tricas
- DocumentaciÃ³n completa

### Futuras Mejoras ğŸš€
- IntegraciÃ³n con bases de datos vectoriales
- API REST para integraciÃ³n externa
- Sistema de cachÃ© para optimizar rendimiento
- Interfaz administrativa para gestiÃ³n de contenido

## ğŸ‘¥ Contributors

### Equipo de Desarrollo

- **[Daniela GÃ³mez Ayalde](https://github.com/DanielaGomez98)** - @DanielaGomez98
- **[Alejandro Arteaga](https://github.com/alejandroarteagaj)** - @alejandroarteagaj
- **[Juan Camilo Giraldo](https://github.com/Raldo26)** - @Raldo26
- **[Juan Felipe HernÃ¡ndez](https://github.com/Juanhernandez1972)** - @Juanhernandez1972

### MetodologÃ­a de Trabajo

- **Code Review**: RevisiÃ³n cruzada de cÃ³digo entre miembros del equipo
- **DocumentaciÃ³n Compartida**: Mantenimiento colaborativo de documentaciÃ³n tÃ©cnica

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

### Ãreas de ContribuciÃ³n
- Mejora de prompts y modelos
- Nuevas fuentes de informaciÃ³n
- OptimizaciÃ³n de rendimiento
- Testing y validaciÃ³n
- DocumentaciÃ³n y ejemplos

## ğŸ“ Contacto

Para preguntas o sugerencias sobre este centro de informaciÃ³n, por favor contacta al equipo de desarrollo.

---

**Â¡Explora el mundo de Colombina con inteligencia artificial! ğŸ­**