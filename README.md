# ğŸ­ Centro de InformaciÃ³n Colombina

Un sistema integral de inteligencia artificial especializado en **Colombina**, desarrollado en dos entregas que evolucionaron desde un chatbot bÃ¡sico hasta un agente conversacional avanzado con mÃºltiples herramientas de IA.

## ğŸ“‹ EvoluciÃ³n del Proyecto

### ğŸ“¦ Primera Entrega: FundaciÃ³n del Sistema
**Objetivo:** Crear la infraestructura base de datos y anÃ¡lisis de informaciÃ³n corporativa

### ğŸ“¦ Segunda Entrega: Agente Conversacional Avanzado  
**Objetivo:** Implementar un sistema RAG completo con memoria conversacional y herramientas especializadas

---

## ğŸŒŸ CaracterÃ­sticas por Entrega

### ğŸ”¹ Primera Entrega - Infraestructura y AnÃ¡lisis

#### Funcionalidades Implementadas:
- **ğŸ•·ï¸ Web Scraping Completo**: ExtracciÃ³n automÃ¡tica del sitio oficial de Colombina
- **ğŸ“„ Procesamiento de Documentos**: Sistema de limpieza y estructuraciÃ³n de contenido
- **ğŸ“Š AnÃ¡lisis de Contenido**: GeneraciÃ³n de insights y mÃ©tricas
- **â“ Sistema de FAQs**: GeneraciÃ³n automÃ¡tica de preguntas frecuentes
- **ğŸ“‹ Resumen Ejecutivo**: AnÃ¡lisis integral de informaciÃ³n corporativa
- **ğŸ”„ Pipeline de Chunking**: DivisiÃ³n inteligente de contenido
- **ğŸ“š Base de Conocimiento**: EstructuraciÃ³n de informaciÃ³n corporativa
- **ğŸ¯ Interfaz Streamlit BÃ¡sica**: Chatbot simple con 4 pestaÃ±as (chatbot.py)
- **ğŸ¤– Chatbot con Modelo Local**: Sistema Q&A usando Ollama sin vectorizaciÃ³n

#### MÃ³dulos Desarrollados:
```
â”œâ”€â”€ web_scraping/              # Sistema de extracciÃ³n web
â”œâ”€â”€ preprocessing/             # Procesamiento de datos
â”œâ”€â”€ chunking/                  # DivisiÃ³n de contenido
â”œâ”€â”€ knowledge_base/            # Base de conocimiento
â”œâ”€â”€ llm/                       # MÃ³dulos de IA bÃ¡sicos
â”‚   â”œâ”€â”€ FAQ/                   # Generador de FAQs
â”‚   â”œâ”€â”€ QA/                    # Sistema Q&A bÃ¡sico
â”‚   â””â”€â”€ summary/               # Generador de resÃºmenes
â”œâ”€â”€ logging_util/              # Sistema de logging
â””â”€â”€ chatbot.py                 # Interfaz Streamlit bÃ¡sica (4 pestaÃ±as)
```

### ğŸ”¹ Segunda Entrega - Agente Conversacional RAG

#### Nuevas Funcionalidades:
- **ğŸ¤– Agente Conversacional**: Sistema LangGraph con memoria persistente
- **ğŸ” Sistema RAG Avanzado**: Retrieval-Augmented Generation con ChromaDB
- **ğŸ› ï¸ Herramientas Especializadas**: Tools para datos estructurados y RAG
- **ğŸ’­ Memoria Conversacional**: Contexto persistente entre sesiones
- **ğŸ”„ Sistema de Fallback**: LÃ³gica inteligente entre herramientas
- **ğŸ¯ Interfaz Streamlit Avanzada**: AplicaciÃ³n web con agente conversacional (app.py)

#### Nuevos MÃ³dulos:
```
â”œâ”€â”€ RAG/                       # ğŸ†• Sistema RAG completo
â”‚   â”œâ”€â”€ agent/                 # Agente conversacional
â”‚   â”‚   â”œâ”€â”€ colombina_agent.py # Agente principal LangGraph
â”‚   â”‚   â”œâ”€â”€ tool_rag.py        # Herramienta RAG
â”‚   â”‚   â””â”€â”€ tool_structured_data.py # Herramienta datos estructurados
â”‚   â”œâ”€â”€ vector_db/             # Base de datos vectorial
â”‚   â”‚   â””â”€â”€ load_data.py       # Carga de embeddings
â”‚   â””â”€â”€ chroma_db/             # ChromaDB persistente
â””â”€â”€ app.py                     # ğŸ†• Interfaz Streamlit
```

---

## ğŸš€ TecnologÃ­as Utilizadas

### Primera Entrega - FundaciÃ³n
- **Python 3.13+** - Lenguaje base
- **Selenium + BeautifulSoup** - Web scraping
- **OpenAI GPT-4o** - GeneraciÃ³n de contenido
- **Ollama (gpt-oss:20b)** - Modelos locales sin vectorizaciÃ³n
- **Streamlit** - Interfaz web bÃ¡sica (chatbot.py)
- **JSON/CSV** - Almacenamiento de datos
- **Logging personalizado** - Trazabilidad

### Segunda Entrega - Avances
- **LangChain + LangGraph** - Framework de agentes
- **ChromaDB** - Base de datos vectorial
- **OpenAI Embeddings** - VectorizaciÃ³n de texto
- **Streamlit Avanzado** - Interfaz web con agente (app.py)
- **Memory Persistence** - GestiÃ³n de estado
- **Tool Orchestration** - CoordinaciÃ³n de herramientas

---

## ğŸ”§ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos
- Python 3.13 o superior
- API Key de OpenAI
- Ollama instalado (para funciones de primera entrega)
- Chrome/Chromium (para web scraping)

### InstalaciÃ³n
```bash
# Clonar repositorio
git clone <url-del-repositorio>
cd chatbot_colombina

# Crear entorno virtual
uv venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Instalar dependencias
uv pip install -r requirements.txt

# Configurar variables de entorno
echo "OPENAI_API_KEY=tu_api_key_aqui" > .env

# Instalar Ollama (opcional, para primera entrega)
ollama pull gpt-oss:20b
```

---

## ğŸƒâ€â™‚ï¸ Uso del Sistema

### ğŸ¯ Agente Conversacional (Segunda Entrega)
```bash
# Interfaz principal Streamlit con agente RAG
streamlit run app.py
```
**Funcionalidades:**
- ConversaciÃ³n natural con memoria persistente
- Consultas sobre Colombina usando RAG
- Datos estructurados (contacto, horarios, NIT)
- Sistema de fallback inteligente

### ğŸ“Š Interfaz BÃ¡sica y Herramientas de AnÃ¡lisis (Primera Entrega)

#### Interfaz Streamlit Original
```bash
# Interfaz bÃ¡sica con 4 pestaÃ±as (modelo local sin RAG)
streamlit run chatbot.py
```
**Funcionalidades:**
- Sistema Q&A con modelo local (Ollama)
- GeneraciÃ³n de FAQs
- Resumen ejecutivo
- Chatbot bÃ¡sico con OpenAI

#### Herramientas Individuales

#### Sistema de FAQs
```bash
python llm/FAQ/faq_ollama.py
```

#### Generador de ResÃºmenes
```bash
python llm/summary/generate_summary.py
```

#### Sistema Q&A BÃ¡sico
```bash
python llm/QA/qa_ollama.py
```

#### Web Scraping
```bash
python web_scraping/scripts/advanced_scraper.py
```

#### Procesamiento de Datos
```bash
# Limpiar archivos
python preprocessing/clean_md_files.py

# Generar chunks
python chunking/chunking.py

# Preparar base de conocimiento
python knowledge_base/clean_kb.py
```

---

## ğŸ“ Arquitectura del Sistema

### Flujo de Datos - Primera Entrega
```
Web Scraping â†’ Preprocessing â†’ Chunking â†’ Knowledge Base
     â†“
AnÃ¡lisis (FAQs, Q&A, ResÃºmenes) â†’ Streamlit Interface (chatbot.py)
     â†“
Modelo Local (Ollama) sin vectorizaciÃ³n â†’ Respuestas BÃ¡sicas
```

### Flujo de Datos - Segunda Entrega
```
Knowledge Base â†’ Vector DB (ChromaDB) â†’ RAG System
                      â†“
User Input â†’ LangGraph Agent â†’ Tools (RAG/Structured Data) â†’ Response
                      â†“
                Memory Persistence â†’ Streamlit Interface (app.py)
```

---

## ï¿½ Componentes Clave por Entrega

### Primera Entrega

#### [`web_scraping/scripts/advanced_scraper.py`](web_scraping/scripts/advanced_scraper.py)
Sistema robusto de extracciÃ³n con categorizaciÃ³n automÃ¡tica y manejo de errores.

#### [`chunking/chunking.py`](chunking/chunking.py)
DivisiÃ³n inteligente de contenido para optimizaciÃ³n de consultas.

#### [`llm/summary/generate_summary.py`](llm/summary/generate_summary.py)
AnÃ¡lisis ejecutivo de informaciÃ³n corporativa.

#### [`chatbot.py`](chatbot.py)
Interfaz Streamlit original con 4 pestaÃ±as: chatbot, Q&A, FAQs y resumen ejecutivo. Utiliza modelos locales sin vectorizaciÃ³n.

### Segunda Entrega

#### [`RAG/agent/colombina_agent.py`](RAG/agent/colombina_agent.py)
Agente principal con LangGraph, memoria conversacional y orquestaciÃ³n de herramientas.

#### [`RAG/agent/tool_rag.py`](RAG/agent/tool_rag.py)
Herramienta RAG con ChromaDB y contextualizaciÃ³n de consultas.

#### [`RAG/agent/tool_structured_data.py`](RAG/agent/tool_structured_data.py)
Acceso a datos fÃ¡cticos especÃ­ficos (contacto, horarios, NIT).

#### [`app.py`](app.py)
Interfaz Streamlit con gestiÃ³n de sesiones y memoria persistente.

---

## ğŸ“Š MÃ©tricas y Resultados

### Primera Entrega - Cobertura de Datos
- **294 URLs** extraÃ­das del sitio oficial
- **130 chunks** optimizados generados
- **26 documentos** principales procesados
- **Sistema de logging** implementado

### Segunda Entrega - Funcionalidad Avanzada
- **Memoria conversacional** funcional
- **Sistema RAG** con bÃºsqueda semÃ¡ntica
- **2 herramientas especializadas** integradas
- **Interfaz web** interactiva
- **Fallback inteligente** implementado

---

## ğŸ§ª EvaluaciÃ³n y Testing

### Primera Entrega
```bash
# EvaluaciÃ³n en notebooks
jupyter lab tests/Taller1.ipynb
```

### Segunda Entrega
```bash
# Testing del agente
python RAG/agent/colombina_agent.py

# Testing de herramientas individuales
python RAG/agent/tool_rag.py
python RAG/agent/tool_structured_data.py
```

---

## ğŸ”’ Mejores PrÃ¡cticas Implementadas

### Ambas Entregas
- âœ… API Keys en variables de entorno
- âœ… Logging comprehensivo sin informaciÃ³n sensible
- âœ… Manejo robusto de errores
- âœ… SeparaciÃ³n clara entre datos y cÃ³digo
- âœ… DocumentaciÃ³n tÃ©cnica completa

### Segunda Entrega - Adicionales
- âœ… GestiÃ³n de estado con LangGraph
- âœ… Memory persistence entre sesiones
- âœ… Tool orchestration con fallback
- âœ… Interfaz de usuario intuitiva
- âœ… Arquitectura modular escalable

---

## ï¿½ Roadmap de Desarrollo

### âœ… Primera Entrega (Completada)
- Infraestructura de datos
- Sistemas de anÃ¡lisis bÃ¡sico
- Pipeline de procesamiento
- Herramientas de extracciÃ³n

### âœ… Segunda Entrega (Completada)
- Agente conversacional RAG
- Memoria persistente
- Interfaz web interactiva
- Sistema de herramientas

---

## ğŸ‘¥ Contributors

### Equipo de Desarrollo

- **[Daniela GÃ³mez Ayalde](https://github.com/DanielaGomez98)** - @DanielaGomez98
- **[Nombre Desarrollador 2](https://github.com/usuario2)** - @usuario2  
- **[Nombre Desarrollador 3](https://github.com/usuario3)** - @usuario3
- **[Nombre Desarrollador 4](https://github.com/usuario4)** - @usuario4

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

### Ãreas de ContribuciÃ³n
- Mejora de prompts y modelos
- Nuevas fuentes de informaciÃ³n
- OptimizaciÃ³n de rendimiento
- Testing y validaciÃ³n
- DocumentaciÃ³n y ejemplos
- Nuevas herramientas para el agente

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia Apache 2.0. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ”„ Changelog

### v2.0.0 - Segunda Entrega (2025-11-06)
- âœ¨ **NUEVO:** Agente conversacional con LangGraph
- âœ¨ **NUEVO:** Sistema RAG con ChromaDB
- âœ¨ **NUEVO:** Herramientas especializadas (RAG + datos estructurados)
- âœ¨ **NUEVO:** Memoria conversacional persistente
- âœ¨ **NUEVO:** Interfaz Streamlit interactiva
- âœ¨ **NUEVO:** Sistema de fallback inteligente
- ï¿½ **Mejorado:** Logging con emojis y mejor trazabilidad

### v1.0.0 - Primera Entrega (2025-10-XX)
- ğŸ‰ **Inicial:** Sistema de web scraping completo
- ğŸ‰ **Inicial:** Pipeline de procesamiento de datos
- ğŸ‰ **Inicial:** Generador de FAQs automÃ¡tico
- ğŸ‰ **Inicial:** Sistema Q&A con Ollama (modelo local)
- ğŸ‰ **Inicial:** Resumen ejecutivo automatizado
- ğŸ‰ **Inicial:** Base de conocimiento estructurada
- ğŸ‰ **Inicial:** Sistema de logging personalizado
- ğŸ‰ **Inicial:** Interfaz Streamlit bÃ¡sica (chatbot.py) sin vectorizaciÃ³n

---

**Â¡Explora el mundo de Colombina con inteligencia artificial avanzada! ğŸ­ğŸ¤–**

## ğŸš€ TecnologÃ­as Utilizadas

### Backend y IA
- **Python 3.13+**
- **LangChain** - Framework para LLMs y RAG
- **OpenAI GPT-4o** - Modelo principal para el chatbot
- **Ollama** - Modelos locales (gpt-oss:20b)
- **Streamlit** - Interfaz web multi-tab

### Web Scraping y Procesamiento
- **Selenium** - AutomatizaciÃ³n web avanzada
- **BeautifulSoup4** - Parsing HTML
- **PyPDF2** - ExtracciÃ³n de contenido PDF
- **RecursiveCharacterTextSplitter** - Chunking inteligente

### Almacenamiento y Logging
- **JSON** - Base de conocimiento estructurada
- **CSV** - ExportaciÃ³n de datos
- **Logging personalizado** - Sistema de trazabilidad

## ğŸ“‹ Requisitos Previos

- Python 3.13 o superior
- API Key de OpenAI
- Ollama instalado (para funciones Q&A y FAQ)
- Chrome/Chromium (para web scraping)
- ConexiÃ³n a internet

## ğŸ”§ InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone <url-del-repositorio>
cd chatbot_colombina
```

2. **Instalar dependencias**
```bash
uv venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows
uv pip install -r pyproject.toml
```

3. **Configurar variables de entorno**
```bash
# Crear archivo .env en la raÃ­z del proyecto
echo "OPENAI_API_KEY=tu_api_key_aqui" > .env
```

4. **Instalar Ollama (opcional, para Q&A local)**
```bash
# Instalar Ollama desde https://ollama.ai
ollama pull gpt-oss:20b
```

## ğŸƒâ€â™‚ï¸ Uso

### Interfaz Principal (Streamlit)
```bash
streamlit run chatbot.py
```

La aplicaciÃ³n incluye 4 pestaÃ±as principales:

#### ğŸ” **Consulta Q&A**
- Sistema de preguntas y respuestas usando modelos locales
- Preguntas predefinidas sobre Colombina
- ParÃ¡metros configurables (temperatura, top_p)

#### â“ **Preguntas Frecuentes** 
- GeneraciÃ³n automÃ¡tica de FAQs basadas en la base de conocimiento
- ExportaciÃ³n en formato texto
- AnÃ¡lisis de 25 fragmentos de contenido mÃ¡s relevantes

#### ğŸ“‹ **Resumen Ejecutivo**
- Resumen completo de informaciÃ³n corporativa
- AnÃ¡lisis de historia, sostenibilidad, productos y logros
- ExportaciÃ³n en formato texto

#### ğŸ’¬ **Chatbot Interactivo**
- ConversaciÃ³n natural con GPT-4o
- Memoria de conversaciÃ³n por sesiÃ³n
- Respuestas especializadas en Colombina

### Funciones Individuales

#### Web Scraping
```bash
# ExtracciÃ³n bÃ¡sica de links
python web_scraping/scripts/extract_colombina_links.py

# Scraping avanzado con contenido completo
python web_scraping/scripts/advanced_scraper.py
```

#### Procesamiento de Datos
```bash
# Limpiar archivos markdown y crear la base de conocimiento
python preprocessing/clean_md_files.py

# Limpiar base de conocimiento
python knowledge_base/clean_kb.py

# Generar chunks
python chunking/chunking.py
```

#### Sistemas de IA Individuales
```bash
# Generar FAQs
python llm/FAQ/faq_ollama.py

# Sistema Q&A
python llm/QA/qa_ollama.py

# Generar resumen
python llm/summary/generate_summary.py
```

## ğŸ“ Estructura del Proyecto

```
chatbot_colombina/
â”œâ”€â”€ chatbot.py                     # ğŸ¯ Interfaz principal Streamlit
â”œâ”€â”€ requirements.txt               # ğŸ“¦ Dependencias del proyecto
â”œâ”€â”€ pyproject.toml                # âš™ï¸ ConfiguraciÃ³n del proyecto
â”œâ”€â”€ 
â”œâ”€â”€ llm/                          # ğŸ¤– MÃ³dulos de IA
â”‚   â”œâ”€â”€ llm_openai.py            # OpenAI GPT-4o integration
â”‚   â”œâ”€â”€ FAQ/
â”‚   â”‚   â””â”€â”€ faq_openai.py        # Generador de FAQs
â”‚   â”œâ”€â”€ QA/
â”‚   â”‚   â””â”€â”€ qa_ollama.py         # Sistema Q&A con Ollama
â”‚   â””â”€â”€ summary/
â”‚       â””â”€â”€ generate_summary.py  # Generador de resÃºmenes
â”‚
â”œâ”€â”€ web_scraping/                 # ğŸ•·ï¸ Sistema de scraping
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ extract_colombina_links.py
â”‚   â”‚   â””â”€â”€ advanced_scraper.py   # Scraper principal
â”‚   â”œâ”€â”€ colombina_advanced/       # Datos extraÃ­dos
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚       â”œâ”€â”€ noticias/
â”‚   â”‚       â””â”€â”€ otros/
â”‚   â””â”€â”€ pdf_extraction/           # PDFs procesados
â”‚       â””â”€â”€ markdown/
â”‚
â”œâ”€â”€ preprocessing/                # ğŸ”„ Procesamiento de datos
â”‚   â”œâ”€â”€ clean_md_files.py        # Limpieza de markdown
â”‚   â”œâ”€â”€ selected_md_files/       # Archivos seleccionados
â”‚   â””â”€â”€ cleaned_md_files/        # Archivos procesados
â”‚
â”œâ”€â”€ chunking/                     # âœ‚ï¸ DivisiÃ³n de contenido
â”‚   â”œâ”€â”€ chunking.py              # GeneraciÃ³n de chunks
â”‚   â””â”€â”€ chunks.json              # Chunks para RAG
â”‚
â”œâ”€â”€ knowledge_base/              # ğŸ“š Base de conocimiento
â”‚   â”œâ”€â”€ knowledge_base.txt       # Base original
â”‚   â”œâ”€â”€ improved_knowledge_base.txt # Base mejorada
â”‚   â””â”€â”€ clean_kb.py             # Script de limpieza
â”‚
â”œâ”€â”€ logging_util/               # ğŸ“Š Sistema de logging
â”‚   â”œâ”€â”€ logger.py              # ConfiguraciÃ³n de logs
â”‚   â””â”€â”€ logs/                  # Archivos de log
â”‚
â””â”€â”€ tests/                     # ğŸ§ª Pruebas y anÃ¡lisis
    â””â”€â”€ Taller1.ipynb         # Notebooks de evaluaciÃ³n
```

## âš™ï¸ ConfiguraciÃ³n Avanzada

### ParÃ¡metros del Modelo

#### Chatbot Interactivo (GPT-4o)
- **ğŸŒ¡ï¸ Temperatura (0.0-1.0)**: Creatividad de respuestas (default: 0.1)
- **ğŸ¯ Top P (0.0-1.0)**: Diversidad de vocabulario (default: 0.9)

#### Sistema Q&A (Ollama)
- **Modelo**: gpt-oss:20b (configurable)
- **Chunks mÃ¡ximos**: 25 fragmentos por consulta
- **TamaÃ±o de chunk**: 1000 caracteres con overlap de 200

#### Web Scraping
- **CategorÃ­as**: noticias, productos, sostenibilidad, otros
- **Formato de salida**: Markdown enriquecido con metadatos
- **LÃ­mite de URLs**: Configurable (294 URLs totales detectadas)

### Sistema de Logging
```python
# ConfiguraciÃ³n en logging_util/logger.py
- RotaciÃ³n automÃ¡tica de archivos
- Niveles: DEBUG, INFO, WARNING, ERROR
- Formato timestamped con colores
- Archivos separados por mÃ³dulo
```

## ğŸ’¬ Ejemplos de Uso

### Preguntas de Ejemplo para Q&A
- "Â¿CÃ³mo se llama el programa de Colombina para acompaÃ±ar a sus proveedores y emprendedores?"
- "Â¿QuÃ© porcentaje de la energÃ­a elÃ©ctrica que utiliza Colombina en Colombia proviene de fuentes renovables?"
- "Â¿CuÃ¡les son los principales logros de Colombina en materia de sostenibilidad relacionados con la energÃ­a y el agua?"
- "Â¿CuÃ¡ndo y cÃ³mo fue fundada Colombina?"
- "Â¿En cuÃ¡ntos paÃ­ses tiene presencia la empresa actualmente?"

### Consultas para el Chatbot
- "Â¿QuÃ© productos fabrica Colombina?"
- "CuÃ©ntame sobre la historia de Bon Bon Bum"
- "Â¿QuÃ© ingredientes tienen los chocolates Nucita?"
- "Â¿DÃ³nde puedo comprar productos Colombina?"
- "Â¿CuÃ¡les son las iniciativas de sostenibilidad de la empresa?"

## ğŸ” Base de Conocimiento

### Fuentes de InformaciÃ³n
- **Sitio Web Oficial**: 294 URLs categorizadas y procesadas
- **Informes Anuales**: PDFs extraÃ­dos y convertidos a texto
- **Documentos Corporativos**: CÃ³digos de conducta, polÃ­ticas
- **Noticias**: Lanzamientos, colaboraciones, logros

### Cobertura TemÃ¡tica
- **ğŸ“ˆ Historia y ExpansiÃ³n**: FundaciÃ³n, crecimiento, internacionalizaciÃ³n
- **ğŸŒ± Sostenibilidad**: EnergÃ­a renovable, gestiÃ³n de residuos, huella de carbono
- **ğŸ¬ Productos**: CatÃ¡logo completo, marcas, innovaciones
- **ğŸ‘¥ Responsabilidad Social**: Programas comunitarios, equidad de gÃ©nero
- **ğŸ’¼ InformaciÃ³n Corporativa**: Gobierno, finanzas, certificaciones
- **ğŸ“ Contacto**: Proveedores, servicio al cliente, sedes

## ğŸ› ï¸ Desarrollo y Arquitectura

### Flujo de Datos
1. **ExtracciÃ³n**: [`advanced_scraper.py`](web_scraping/scripts/advanced_scraper.py) â†’ sitio web
2. **Procesamiento**: [`clean_md_files.py`](preprocessing/clean_md_files.py) â†’ archivos limpios
3. **Chunking**: [`chunking.py`](chunking/chunking.py) â†’ fragmentos para RAG
4. **IA**: Modelos locales (Ollama) y remotos (OpenAI)

### Componentes Clave

#### [`chatbot.py`](chatbot.py)
Interfaz principal con 4 tabs especializados, configuraciÃ³n de parÃ¡metros y manejo de estado.

#### [`llm/llm_openai.py`](llm/llm_openai.py)
Core del chatbot con prompt especializado y manejo de errores.

#### [`web_scraping/scripts/advanced_scraper.py`](web_scraping/scripts/advanced_scraper.py)
Scraper robusto con categorizaciÃ³n automÃ¡tica y manejo de errores.

#### [`chunking/chunking.py`](chunking/chunking.py)
Sistema de divisiÃ³n inteligente de contenido para optimizar el RAG.

### Agregar Nuevas Funcionalidades

1. **Modificar prompts**: Editar templates en mÃ³dulos LLM
2. **Agregar fuentes**: Extender el scraper o agregar procesadores
3. **Nuevos modelos**: Integrar en [`llm/`](llm/) con configuraciÃ³n similar
4. **Mejorar chunking**: Ajustar parÃ¡metros en [`chunking.py`](chunking/chunking.py)
5. **Extend UI**: Agregar tabs en [`chatbot.py`](chatbot.py)

## ğŸ“Š MÃ©tricas y EvaluaciÃ³n

### Cobertura de InformaciÃ³n
- **294 URLs** procesadas del sitio oficial
- **130 chunks** generados para RAG
- **26 documentos** principales procesados
- **Multiple PDFs** de informes anuales integrados

### Rendimiento del Sistema
- **Tiempo de respuesta Q&A**: ~1-2 minutos (modelo local)
- **Tiempo de respuesta Chatbot**: ~5-10 segundos (OpenAI)
- **PrecisiÃ³n evaluada**: Sistema de evaluaciÃ³n en [`tests/Taller1.ipynb`](tests/Taller1.ipynb)

## ğŸ”’ Seguridad y Mejores PrÃ¡cticas

- âœ… API Keys en variables de entorno
- âœ… Logs sin informaciÃ³n sensible
- âœ… ValidaciÃ³n de entrada en todos los mÃ³dulos
- âœ… Manejo robusto de errores y excepciones
- âœ… SeparaciÃ³n clara entre datos y cÃ³digo
- âœ… Licencia Apache 2.0 para uso comercial

## ğŸ› SoluciÃ³n de Problemas

### Errores Comunes

#### "Falta la API Key de OpenAI"
```bash
# Verificar archivo .env
cat .env
# Debe contener: OPENAI_API_KEY=sk-...
```

#### "Ollama model not found"
```bash
# Instalar modelo requerido
ollama pull gpt-oss:20b
```

#### Error en Web Scraping
```bash
# Verificar Chrome/Chromium instalado
# Revisar logs en logging_util/logs/
```

#### Chunks no generados
```bash
# Verificar base de conocimiento
python chunking/chunking.py
# Revisar knowledge_base/improved_knowledge_base.txt
```

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia Apache 2.0. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸš§ Estado del Proyecto

**VersiÃ³n actual: 1.0.0**

### Completado âœ…
- Sistema completo de web scraping
- Pipeline de procesamiento de datos
- 4 interfaces de IA especializadas
- Base de conocimiento integral
- Sistema de logging avanzado
- EvaluaciÃ³n y mÃ©tricas
- DocumentaciÃ³n completa

### Futuras Mejoras ğŸš€
- IntegraciÃ³n con bases de datos vectoriales
- API REST para integraciÃ³n externa
- Sistema de cachÃ© para optimizar rendimiento
- Interfaz administrativa para gestiÃ³n de contenido

## ğŸ‘¥ Contributors

### Equipo de Desarrollo

- **[Daniela GÃ³mez Ayalde](https://github.com/DanielaGomez98)** - @DanielaGomez98
- **[Alejandro Arteaga](https://github.com/alejandroarteagaj)** - @alejandroarteagaj
- **[Juan Camilo Giraldo](https://github.com/Raldo26)** - @Raldo26
- **[Juan Felipe HernÃ¡ndez](https://github.com/Juanhernandez1972)** - @Juanhernandez1972

### MetodologÃ­a de Trabajo

- **Code Review**: RevisiÃ³n cruzada de cÃ³digo entre miembros del equipo
- **DocumentaciÃ³n Compartida**: Mantenimiento colaborativo de documentaciÃ³n tÃ©cnica

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

### Ãreas de ContribuciÃ³n
- Mejora de prompts y modelos
- Nuevas fuentes de informaciÃ³n
- OptimizaciÃ³n de rendimiento
- Testing y validaciÃ³n
- DocumentaciÃ³n y ejemplos

## ğŸ“ Contacto

Para preguntas o sugerencias sobre este centro de informaciÃ³n, por favor contacta al equipo de desarrollo.

---

**Â¡Explora el mundo de Colombina con inteligencia artificial! ğŸ­**