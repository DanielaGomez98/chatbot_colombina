import streamlit as st
from llm.QA.qa_openai import procesar_pregunta_colombina

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(page_title="Chatbot Colombina", page_icon="ğŸ­", layout="wide")

# TÃ­tulo y descripciÃ³n
st.title("ğŸ­ Asistente Virtual de Colombina")

st.markdown("""
Â¡Bienvenido al asistente virtual de **Colombina**! 

**Â¿CÃ³mo funciona?**
- ğŸ’¬ **ConversaciÃ³n simple**: Haz preguntas sobre productos, servicios o informaciÃ³n de Colombina
- ğŸ¬ **Conocimiento especializado**: InformaciÃ³n actualizada sobre dulces, chocolates y productos Colombina
- âš¡ **Respuestas rÃ¡pidas**: ObtÃ©n informaciÃ³n instantÃ¡nea sobre lo que necesites

**Â¡Comienza** preguntando sobre productos, ingredientes, disponibilidad o cualquier tema relacionado con Colombina!
""")

with st.sidebar:
    st.header("ğŸ› ï¸ ParÃ¡metros de ConfiguraciÃ³n")
    
    # ParÃ¡metros del modelo
    temperatura = st.slider(
        "ğŸŒ¡ï¸ Temperatura",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.1,
        help="Controla la creatividad de las respuestas. Valores mÃ¡s altos = mÃ¡s creatividad"
    )
    
    top_p = st.slider(
        "ğŸ¯ Top P",
        min_value=0.0,
        max_value=1.0,
        value=0.9,
        step=0.05,
        help="Controla la diversidad de las respuestas. Valores mÃ¡s bajos = mÃ¡s enfoque"
    )
    
    # Separador
    st.divider()
    
    if st.session_state.get("messages", []):
        if st.button("ğŸ—‘ï¸ Limpiar ConversaciÃ³n", 
                     type="secondary", 
                     help="Borrar todo el historial de la conversaciÃ³n",
                     use_container_width=True):
            st.session_state.messages = []
            st.rerun()

# Inicializar el historial de mensajes
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar historial de conversaciÃ³n
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Input del usuario
user_input = st.chat_input("PregÃºntame sobre productos Colombina, ingredientes, disponibilidad... ğŸ­")

if user_input:
    # Agregar mensaje del usuario al historial
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # Mostrar mensaje del usuario
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # Procesar respuesta del asistente
    with st.spinner("Pensando..."):
        try:
            # AquÃ­ llamas a tu funciÃ³n real del chatbot
            respuesta = procesar_pregunta_colombina(user_input, temperatura, top_p)
            
            # Mostrar respuesta del asistente
            with st.chat_message("assistant"):
                st.markdown(respuesta)
            
            # Agregar respuesta al historial
            st.session_state.messages.append({"role": "assistant", "content": respuesta})
            
        except Exception as e:
            error_message = f"âš ï¸ OcurriÃ³ un error: {e}"
            
            with st.chat_message("assistant"):
                st.markdown(error_message)
            
            st.session_state.messages.append({"role": "assistant", "content": error_message})